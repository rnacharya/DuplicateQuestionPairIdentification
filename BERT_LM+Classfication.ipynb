{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT LM+Classfication.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Z4FEUggBQz",
        "colab_type": "code",
        "outputId": "af03223e-99cc-4605-9b88-94babb5dcf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(\"My GPU Name is: \",gpu.name)\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " \n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=1bb06d4c413ed6e458da0506939d5a1e84d24279ea7a293276137cee862f2322\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "My GPU Name is:  Tesla P100-PCIE-16GB\n",
            "Gen RAM Free: 26.4 GB  | Proc size: 155.8 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaZLqI1LgEPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfYlh4FIpsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePIaLYKFIvRr",
        "colab_type": "code",
        "outputId": "7eba00e3-da58-4b14-f94f-c8fa5fda73a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# do I have GPU:\n",
        "gpu_available = torch.cuda.is_available()\n",
        "print(gpu_available)\n",
        "device = torch.device(\"cuda\" if gpu_available else \"cpu\")\n",
        "# number of GPUs I have:\n",
        "num = torch.cuda.device_count()\n",
        "print(f'I have {num} GPUs')\n",
        "\n",
        "# current device index\n",
        "idx = torch.cuda.current_device()\n",
        "print(f'My current device has index {idx}')\n",
        "\n",
        "# GPU's name\n",
        "name = torch.cuda.get_device_name(idx)\n",
        "print(f'My GPU is {name}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "I have 1 GPUs\n",
            "My current device has index 0\n",
            "My GPU is Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHSioiTkIzGb",
        "colab_type": "code",
        "outputId": "dbeeb993-3ef9-41b1-d923-0c08af8b5dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/08/4a6768ca1a7a4fa37e5ee08077c5d02b8d83876bd36caa5fc24d98992ac2/transformers-2.2.2-py3-none-any.whl (387kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 2.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.40)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=d093db66f212ef02d110b4b736730da00b7a39a96a655d4b67c1cb6e32c4137f\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.85 transformers-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJZ8jOIjI4ca",
        "colab_type": "code",
        "outputId": "7f7b88b5-ee41-49e3-a8cf-f221c35e7b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from pytorch_pretrained_bert import BertAdam\n",
        "#from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mkcVROrCQhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "19fecdbe-3125-4310-e8fa-b667c0010be4"
      },
      "source": [
        "from transformers import BertTokenizer"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-89505a24ece6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJFzsuwt_9v",
        "colab_type": "code",
        "outputId": "03c28dd1-5fb4-4d07-cbc4-51c2a648c168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlSLbYR7aJCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def balancedf(df, size):\n",
        "  size=int(size/2)\n",
        "  df['is_duplicate']=pd.to_numeric(df['is_duplicate'], errors='coerce')\n",
        "  df.dropna(inplace=True)\n",
        "  so_pos=df.loc[df['is_duplicate'] == 1]\n",
        "  so_neg=df.loc[df['is_duplicate'] == 0]\n",
        "  so_pos=so_pos.head(size)\n",
        "  so_neg=so_neg.head(size)\n",
        "  #print(\"Positive: \", so_pos.shape)\n",
        "  #print(\"Negative: \", so_neg.shape)\n",
        "  df=pd.concat([so_pos, so_neg])\n",
        "  #df=df.sample(frac=1)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sodFlhpQI82V",
        "colab_type": "code",
        "outputId": "ad44b4ac-8c9b-41c6-f690-ea40863dabf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "quora_df = pd.read_csv(\"drive/My Drive/Colab Notebooks/train.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "quora_df=balancedf(quora_df, 4000)#1. \n",
        "#4. Only quora, in domain\n",
        "'''quora_df=balancedf(quora_df, 7000)\n",
        "q_pos=quora_df.loc[quora_df['is_duplicate']==1]\n",
        "q_neg=quora_df.loc[quora_df['is_duplicate']==0]\n",
        "print(\"Positive examples:\", q_pos.shape)\n",
        "print(\"Negative examples:\", q_neg.shape)\n",
        "q_train=pd.concat([q_pos.head(3000), au_neg.head(3000)])\n",
        "q_test=pd.concat([q_pos.tail(500), au_neg.tail(500)])\n",
        "df=q_train\n",
        "test_df=q_test'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "so_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/stackoverflow1-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "\n",
        "so_df=balancedf(so_df, 6000)#1. \n",
        "#so_df=balancedf(so_df, 3000)\n",
        "#3 Cross domain, but related genresso_df=balancedf(so_df, 6000)\n",
        "\n",
        "au_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/askubuntu-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "#1,2 \n",
        "au_df=balancedf(au_df, 1000)\n",
        "#3 Cross domain, but related genresau_df=balancedf(au_df, 1000)\n",
        "\n",
        "po_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/politics-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "po_df=balancedf(po_df, 500)\n",
        "\n",
        "mo_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/money-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "mo_df=balancedf(mo_df, 500)\n",
        "\n",
        "#1. All MIX:\n",
        "'''\n",
        "df=pd.concat([au_df,quora_df])\n",
        "df=df.sample(frac=1)\n",
        "test_df=pd.concat([so_df,po_df,mo_df])\n",
        "test_df=test_df.sample(frac=1)\n",
        "print(df.shape)\n",
        "print(test_df.shape)'''\n",
        "\n",
        "#3. Cross domain but related genres\n",
        "df=so_df\n",
        "df=df.sample(frac=1)\n",
        "test_df=au_df\n",
        "test_df=test_df.sample(frac=1)\n",
        "print(df.shape)\n",
        "print(test_df.shape)\n",
        "\n",
        "\n",
        "#2. Joint training but related genres mic: \n",
        "'''au_pos=au_df.loc[au_df['is_duplicate'] == 1]\n",
        "au_neg=au_df.loc[au_df['is_duplicate'] == 0]\n",
        "au_train=pd.concat([au_pos.head(1500), au_neg.head(1500)])\n",
        "au_test=pd.concat([au_pos.tail(500), au_neg.tail(500)])\n",
        "df=pd.concat([au_train,so_df])\n",
        "df=df.sample(frac=1)\n",
        "\n",
        "test_df=pd.concat([au_test])\n",
        "test_df=test_df.sample(frac=1)\n",
        "print(df.shape)\n",
        "print(test_df.shape)\n",
        "'''\n",
        "print(\"Shapes:\")\n",
        "print(df.shape)\n",
        "print(test_df.shape)\n",
        "\n",
        "df['question1']=df['question1'].astype(str)\n",
        "df['question2']=df['question2'].astype(str)\n",
        "df['is_duplicate']=df['is_duplicate'].astype(str)\n",
        "test_df['question1']=test_df['question1'].astype(str)\n",
        "test_df['question2']=test_df['question2'].astype(str)\n",
        "test_df['is_duplicate']=test_df['is_duplicate'].astype(str)\n",
        "dtypeCount =[df.iloc[:,i].apply(type).value_counts() for i in range(df.shape[1])]\n",
        "print(dtypeCount)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(6000, 5)\n",
            "(1000, 5)\n",
            "Shapes:\n",
            "(6000, 5)\n",
            "(1000, 5)\n",
            "[<class 'str'>    6000\n",
            "Name: qid1, dtype: int64, <class 'str'>    6000\n",
            "Name: qid2, dtype: int64, <class 'str'>    6000\n",
            "Name: question1, dtype: int64, <class 'str'>    6000\n",
            "Name: question2, dtype: int64, <class 'str'>    6000\n",
            "Name: is_duplicate, dtype: int64]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPuOdK8QlGA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessdf(df):\n",
        "  numrows,numcols=df.shape\n",
        "  numrows*=2\n",
        "  sumlen=0\n",
        "  vocab=set()\n",
        "  num_duplicates=0\n",
        "  '''df['question1']=df['question1'].str.lower()\n",
        "  df['question1']=df['question1'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "  df['question1']=df['question1'].str.replace('[^\\w\\s]','')\n",
        "  df['question2']=df['question2'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "  df['question2']=df['question2'].str.replace('[^\\w\\s]','')\n",
        "  df['question2']=df['question2'].str.lower()'''\n",
        "  for idx, row in df.iterrows():\n",
        "  #print(row)\n",
        "    q1=row[\"question1\"]\n",
        "    if(q1==\"question1\"):\n",
        "      continue\n",
        "    q2=row[\"question2\"]\n",
        "  #print(q1)\n",
        "  #print(q2)\n",
        "    if(int(float(row[\"is_duplicate\"]))==1):\n",
        "      num_duplicates+=1\n",
        "    sumlen+=len(str(q1))\n",
        "    sumlen+=len(str(q2))\n",
        "    if(\"float\" in str(type(q1)) or \"float\" in str(type(q2))):\n",
        "      continue\n",
        "    vocab.update(q1.split())\n",
        "    vocab.update(q2.split())\n",
        "  print(\"Size of vocabulary:\", len(vocab))  \n",
        "  print(\"Average sequence length: \", int(sumlen/numrows)) \n",
        "  print(\"Number of duplicate questions: \", num_duplicates) \n",
        "#print(df[\"question2\"][1]) \n",
        "  return df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gocXkNlg5p",
        "colab_type": "code",
        "outputId": "cf2a2bfb-beed-4cbf-9143-9e16da6cd668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "df=preprocessdf(test_df)\n",
        "print(df.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary: 2908\n",
            "Average sequence length:  51\n",
            "Number of duplicate questions:  500\n",
            "(1000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrz_wQa-I_Jq",
        "colab_type": "code",
        "outputId": "38ddbf78-38bf-40ee-bac4-ab0ab24ef955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Create sentence and label lists\n",
        "text_a = df.question1\n",
        "text_b=df.question2\n",
        "is_dup=df.is_duplicate\n",
        "questions=[]\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "labels=list()\n",
        "m,n=df.shape\n",
        "print(m)\n",
        "for w in range(0, m):\n",
        "  q1=df.iloc[w,2]\n",
        "  #print(q1)\n",
        "  q2=df.iloc[w,3]\n",
        "  #print(q2)\n",
        "  is_d=int(float(df.iloc[w,4]))\n",
        "  #print(is_d)\n",
        "  if(q1==\"question1\"):\n",
        "    continue\n",
        "  questions.append(\"[CLS] \" + str(q1) + \" [SEP] \" +str(q2)+ \" [SEP]\")\n",
        "  #print(is_d)\n",
        "  labels.append(is_d)\n",
        "#labels = df.is_duplicate.values\n",
        "#labels=list(map(int, labels)) \n",
        "labels=np.asarray(labels)\n",
        "print(len(labels))\n",
        "#print(questions[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb67l2HsJDy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 80\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRwLRqtuoE2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path=\"/lm_finetune\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65nOcg0IoFCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "1425f96c-7f98-465c-b4c8-726e3eda4c74"
      },
      "source": [
        "lm_df=pd.concat([lm_so,lm_mo,lm_po])\n",
        "print(lm_df.shape)\n",
        "q1=lm_df[\"question1\"].values\n",
        "q2=lm_df[\"question2\"].values\n",
        "q= [*q1, *q2]\n",
        "lm_df=pd.DataFrame(q, columns=[\"questions\"])\n",
        "print(lm_df.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b2333461a0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlm_so\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlm_mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlm_po\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lm_so' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKdFrWzsoFPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "8fd47dbd-fee4-487e-f38d-7881617e7084"
      },
      "source": [
        "lm_df.questions = lm_df.questions.str.lower()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-96f5f67e5b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'lm_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWhJFQaLodj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "changed_text=lm_df.questions.apply(lambda x:x+\"\\n\"+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tilt82Zoduo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "open(os.path.join(\"/\",'data_lm.txt'), \"w\").write(''.join(changed_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXB4Jfnqohhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjx4IWOmosfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = directory_path+\"data_lm.txt\" ##copying newly created data to the same finetuned folder.\n",
        "dst = os.getcwd()\n",
        "shutil.copy(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAFPYLs7ovxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZm1VhcMozDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1bab5765-bc14-4b80-b06c-5cd2a54603bd"
      },
      "source": [
        "from transformers import *\n",
        "!python3 '/content/drive/My Drive/Colab Notebooks/run_lm_finetuning.py' --output_dir='/content/drive/My Drive/Colab Notebooks/lm_finetunev2' --model_type=bert  --model_name_or_path=bert-base-uncased --do_train --train_data_file='/content/drive/My Drive/Colab Notebooks/data_lm.txt' --mlm"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'run_lm_finetuning.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGfKb7Zy2xUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelpath=\"/content/drive/My Drive/Colab Notebooks/lm_finetunev2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZoheTzWJBzM",
        "colab_type": "code",
        "outputId": "91c7e3af-14ab-4015-bcb9-de9cdda6adf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(modelpath, do_lower_case=True)\n",
        "\n",
        "input_ids = [tokenizer.encode(sent) for sent in questions]\n",
        "print (\"Tokenize the first sentence:\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_SN8bm2JJNE",
        "colab_type": "code",
        "outputId": "a5a4d689-e20d-40e3-8f4c-79116e6b7006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#print(tokenized_texts[0])\n",
        "##input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "#print(input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 5328, 7221, 3156, 6694, 21766, 28084, 3964, 2634, 102, 2339, 2231, 9225, 21029, 3156, 21766, 28084, 2015, 6694, 21766, 28084, 2015, 9598, 3964, 2634, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_iCD0uEJNJd",
        "colab_type": "code",
        "outputId": "c39d5f71-81ae-4230-ffe1-bb63b8ff7f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "print(input_ids.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYQRss27JN3V",
        "colab_type": "code",
        "outputId": "86cfd07c-1660-4c5c-8aa3-fb266c4f03a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  att_mask = [int(token_id > 0) for token_id in seq]\n",
        "  attention_masks.append(att_mask)\n",
        "  #print(seq_mask)\n",
        "  #print(seq)\n",
        "  #break\n",
        "#print(attention_masks[0]) \n",
        "print(input_ids[0]) \n",
        "print(attention_masks[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101   101  2903 28625  6483  1031 19802  1033  2079  2903  7570  7352\n",
            " 16186  2015  1031 19802  1033   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5cQZCPTJU3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvJbL9J-JXUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5zCHaD4JZf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LebX2rBxJb_M",
        "colab_type": "code",
        "outputId": "03879454-1839-4b16-ea48-b871e04f4954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(modelpath, num_labels=2)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHh8sIKJhl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfw-eSYdOGCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unfreeze_bert_encoder():\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "048N-B0AJj9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ppI-kTJmIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import tensorflow as tf\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    print(labels)\n",
        "    print(pred_flat)\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    return accuracy_score(labels_flat, pred_flat)#tf.metrics.accuracy(labels=tf.argmax(labels_flat, 1),predictions=pred_flat)#accuracy_score(labels_flat, pred_flat)\n",
        "def flat_precision(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    p=precision_score(labels_flat, pred_flat)\n",
        "    \n",
        "    return p\n",
        "\n",
        "\n",
        "def flat_recall(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(labels_flat)\n",
        "    print(pred_flat)\n",
        "    r=recall_score(labels_flat, pred_flat)\n",
        "    \n",
        "    return r        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv78pkRItqC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#train_epochs=list()\n",
        "train_loss=list()\n",
        "#train_accuracy=list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxBN1wIGVCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcVSZ9gTJoWK",
        "colab_type": "code",
        "outputId": "91e8f4a7-e2cf-4234-f8f7-3570835ef91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "model.zero_grad()\n",
        "unfreeze_bert_encoder()\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "        \n",
        "    # This training code is based on the `run_glue.py` script here:\n",
        "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Put the model into training mode.    \n",
        "        model.train()\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "                \n",
        "        # Forward pass (evaluate the model on this training batch)\n",
        "        # `model` is of type: pytorch_pretrained_bert.modeling.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the loss. `loss` is a Tensor containing a single value; \n",
        "        # the `.item()` function just returns the Python value from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        model.zero_grad()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            # Forward pass, calculate logit predictions\n",
        "            # token_type_ids is for the segment ids, but we only have a single sentence here.\n",
        "            # See https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L258 \n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")  "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:15.\n",
            "  Batch   120  of    282.    Elapsed: 0:00:23.\n",
            "  Batch   160  of    282.    Elapsed: 0:00:30.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:38.\n",
            "  Batch   240  of    282.    Elapsed: 0:00:45.\n",
            "  Batch   280  of    282.    Elapsed: 0:00:53.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:00:53\n",
            "\n",
            "Running Validation...\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1]\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0]\n",
            "[1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1]\n",
            "[1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0]\n",
            "[1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1]\n",
            "[1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1]\n",
            "[1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0]\n",
            "[1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0]\n",
            "[0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1]\n",
            "[0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
            "[0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0]\n",
            "[0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1]\n",
            "[1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1]\n",
            "[1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0]\n",
            "[1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1]\n",
            "[1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1]\n",
            "[1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "[1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0]\n",
            "[1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0]\n",
            "[1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1]\n",
            "[1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1]\n",
            "[0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "[1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0]\n",
            "[0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1]\n",
            "[0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0]\n",
            "[0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0]\n",
            "[1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1]\n",
            "[1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1]\n",
            "[1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1]\n",
            "[0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1]\n",
            "[0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1]\n",
            "[0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1]\n",
            "[1 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
            "[0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1]\n",
            "[0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0]\n",
            "[1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0]\n",
            "[1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0]\n",
            "[1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "[1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1]\n",
            "[0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
            "[1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0]\n",
            "[1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1]\n",
            "[0 0 0 1]\n",
            "[0 0 0 1]\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:15.\n",
            "  Batch   120  of    282.    Elapsed: 0:00:23.\n",
            "  Batch   160  of    282.    Elapsed: 0:00:30.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:38.\n",
            "  Batch   240  of    282.    Elapsed: 0:00:45.\n",
            "  Batch   280  of    282.    Elapsed: 0:00:53.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:00:53\n",
            "\n",
            "Running Validation...\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1]\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1]\n",
            "[1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1]\n",
            "[1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0]\n",
            "[1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1]\n",
            "[1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1]\n",
            "[1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0]\n",
            "[1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0]\n",
            "[0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1]\n",
            "[0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0]\n",
            "[0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1]\n",
            "[1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1]\n",
            "[1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0]\n",
            "[1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "[0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1]\n",
            "[1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "[1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0]\n",
            "[1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0]\n",
            "[1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1]\n",
            "[1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1]\n",
            "[0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "[1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0]\n",
            "[1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1]\n",
            "[0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1]\n",
            "[1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1]\n",
            "[1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1]\n",
            "[1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            "[0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1]\n",
            "[0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1]\n",
            "[0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1]\n",
            "[0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1]\n",
            "[0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
            "[1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0]\n",
            "[1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0]\n",
            "[1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "[1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1]\n",
            "[0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
            "[1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0]\n",
            "[1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[0 0 0 1]\n",
            "[0 0 0 1]\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:15.\n",
            "  Batch   120  of    282.    Elapsed: 0:00:23.\n",
            "  Batch   160  of    282.    Elapsed: 0:00:30.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:38.\n",
            "  Batch   240  of    282.    Elapsed: 0:00:45.\n",
            "  Batch   280  of    282.    Elapsed: 0:00:53.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:00:53\n",
            "\n",
            "Running Validation...\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1]\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0]\n",
            "[1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1]\n",
            "[1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0]\n",
            "[1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1]\n",
            "[1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1]\n",
            "[1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0]\n",
            "[1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0]\n",
            "[0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1]\n",
            "[0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0]\n",
            "[0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1]\n",
            "[1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "[1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0]\n",
            "[1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "[1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "[1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0]\n",
            "[1 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0]\n",
            "[1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1]\n",
            "[0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "[1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0]\n",
            "[1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1]\n",
            "[0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1]\n",
            "[1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1]\n",
            "[1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1]\n",
            "[1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            "[0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1]\n",
            "[0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1]\n",
            "[0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1]\n",
            "[0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "[0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1]\n",
            "[0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1]\n",
            "[1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0]\n",
            "[1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0]\n",
            "[1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "[1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
            "[1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0]\n",
            "[1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[0 0 0 1]\n",
            "[0 0 0 1]\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:15.\n",
            "  Batch   120  of    282.    Elapsed: 0:00:23.\n",
            "  Batch   160  of    282.    Elapsed: 0:00:30.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:38.\n",
            "  Batch   240  of    282.    Elapsed: 0:00:45.\n",
            "  Batch   280  of    282.    Elapsed: 0:00:53.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:00:53\n",
            "\n",
            "Running Validation...\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1]\n",
            "[1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0]\n",
            "[1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1]\n",
            "[1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0]\n",
            "[1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1]\n",
            "[1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1]\n",
            "[1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1]\n",
            "[1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0]\n",
            "[1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0]\n",
            "[0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1]\n",
            "[1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0]\n",
            "[0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1]\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0]\n",
            "[0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1]\n",
            "[1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1]\n",
            "[1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0]\n",
            "[1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
            "[1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1]\n",
            "[1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0]\n",
            "[1 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0]\n",
            "[1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1]\n",
            "[0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "[1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0]\n",
            "[0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1]\n",
            "[0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0]\n",
            "[1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1]\n",
            "[1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1]\n",
            "[1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1]\n",
            "[1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            "[0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1]\n",
            "[0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1]\n",
            "[0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1]\n",
            "[0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1]\n",
            "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
            "[0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1]\n",
            "[0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1]\n",
            "[1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0]\n",
            "[1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0]\n",
            "[1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "[1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1]\n",
            "[0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0]\n",
            "[1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0]\n",
            "[1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1]\n",
            "[0 0 0 1]\n",
            "[0 0 0 1]\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODSWJk7OvfGZ",
        "colab_type": "code",
        "outputId": "d1a14659-574a-4570-8bb9-6ec27081f1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1OL2pKp_fbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'classifier-lm-po-mo-so.pt'\n",
        "path = F\"drive/My Drive/Colab Notebooks/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvIWUtgwot4Y",
        "colab_type": "code",
        "outputId": "2a52e5ae-ea96-4b83-f8ce-a82d09afd2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "test_df['question1']=test_df['question1'].astype(str)\n",
        "test_df['question2']=test_df['question2'].astype(str)\n",
        "test_df['is_duplicate']=test_df['is_duplicate'].astype(str)\n",
        "test_df=preprocessdf(test_df)\n",
        "\n",
        "# Create sentence and label lists\n",
        "text_a = test_df.question1\n",
        "text_b=test_df.question2\n",
        "is_dup=test_df.is_duplicate\n",
        "#print(text_a)\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "labels=list()\n",
        "questions=list()\n",
        "m,n=test_df.shape\n",
        "for w in range(m):\n",
        "  q1=test_df.iloc[w,2]\n",
        "  #print(q1)\n",
        "  q2=test_df.iloc[w,3]\n",
        "  #print(q2)\n",
        "  is_d=int(float(test_df.iloc[w,4]))\n",
        "  #print(is_d)\n",
        "  if(q1==\"question1\"):\n",
        "    continue\n",
        "  questions.append(\"[CLS] \" + str(q1) + \" [SEP] \" +str(q2)+ \" [SEP]\")\n",
        "  #print(is_d)\n",
        "  labels.append(is_d)\n",
        "#labels = df.is_duplicate.values\n",
        "labels=np.asarray(labels)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary: 4350\n",
            "Average sequence length:  42\n",
            "Number of duplicate questions:  750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf7Can-1Eus7",
        "colab_type": "code",
        "outputId": "9832ed2f-40e3-4e78-a204-6df1661abc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(test_df.shape)\n",
        "print(len(questions))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 5)\n",
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXBYMc0No5r0",
        "colab_type": "code",
        "outputId": "0c67f85a-9071-4bbf-d2ed-54c1fa24210b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(modelpath, do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.encode(sent[:MAX_LEN]) for sent in questions]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "#print (tokenized_texts[1])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnpqFqYnpm1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = pad_sequences(tokenized_texts, maxlen=MAX_LEN, dtype=\"long\",value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP6M206eqFgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  att_mask = [int(token_id > 0) for token_id in seq]\n",
        "  attention_masks.append(att_mask)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfSXRRfYqLXw",
        "colab_type": "code",
        "outputId": "9370c509-83a4-47ba-bbb2-1436c384a659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "prediction_inputs=input_ids\n",
        "prediction_labels=labels\n",
        "prediction_masks=attention_masks\n",
        "print(prediction_inputs.shape)\n",
        "print(prediction_labels.shape)\n",
        "print(len(prediction_masks))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 80)\n",
            "(1500,)\n",
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOEUZRfso-UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "prediction_inputs = torch.tensor(prediction_inputs)\n",
        "prediction_labels = torch.tensor(prediction_labels)\n",
        "prediction_masks = torch.tensor(prediction_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsPRebtXTfjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 8\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EmsdXHpR_Qr",
        "colab_type": "code",
        "outputId": "738b6c92-c54a-4485-df41-379107422560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,500 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qti7EByKPkEu",
        "colab_type": "code",
        "outputId": "aee08068-df6d-451e-c5de-874a021b3406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "print(\"Final Accuracy: \",accuracy_score(flat_true_labels, flat_predictions))\n",
        "print(\"Precision: \", precision_score(flat_true_labels, flat_predictions))\n",
        "print(\"Recall: \", recall_score(flat_true_labels, flat_predictions))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy:  0.54\n",
            "Precision:  0.8191489361702128\n",
            "Recall:  0.10266666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibK1b_7tS1KY",
        "colab_type": "code",
        "outputId": "21145edb-04d4-41ed-d769-280479cd4e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "print(flat_predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1\n",
            " 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0\n",
            " 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
            " 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0\n",
            " 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0\n",
            " 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
            " 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0\n",
            " 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1\n",
            " 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pxf47CvS6E4",
        "colab_type": "code",
        "outputId": "94de366c-6968-4393-872a-6120cfe98b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "k=0\n",
        "total_incorrect=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  if(int(float(flat_true_labels[i]))!=int(float(test_df.iloc[i,4]))):\n",
        "    print(\"Not correct\")  \n",
        "wrpos=0\n",
        "wrneg=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  pred=int(float(flat_predictions[i]))\n",
        "  real=int(float(flat_true_labels[i]))\n",
        "  if(pred!=real):\n",
        "    total_incorrect+=1\n",
        "    if(flat_true_labels[i]==1):\n",
        "      wrpos+=1\n",
        "    else:\n",
        "      wrneg+=1  \n",
        "    if(k<=11):\n",
        "      print(\"\\n-----------------------------\\n\",test_df.iloc[i,2]+\"\\n\",test_df.iloc[i,3]+\"\\nActual Value: \",test_df.iloc[i,4]+\", \",flat_true_labels[i])\n",
        "    k+=1\n",
        "print(\"Incorrect examples: \",total_incorrect) \n",
        "print(\"Incorrect positive examples: \",wrpos)\n",
        "print(\"incorrect negative examples: \",wrneg)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-----------------------------\n",
            " kinds exchangetraded funds etfs specifically avoided\n",
            " diversifying going long short simultaneously\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " two highinterest loans pay one time split money\n",
            " would anyone want pay debts way highest interest first\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " start savinginvesting retirement\n",
            " best way start investing young person starting career\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " happens cosign loan borrower debtor dies\n",
            " cosigning dying loan cosigner dies estate cosigner liable\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " power monarchs\n",
            " british kings queens veto laws\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " us corporations people\n",
            " benefitsdrawbacks weighted vote based upon federal taxes paid\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " python unicode windows console\n",
            " windows cmd encoding change causes python crash\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " implementing captcha 50 article\n",
            " practical nonimage based captcha approaches\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " worker cooperatives socialist capitalist category\n",
            " good examples countries incorrectly selfidentifying socialist\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " choosing static code analysis tool\n",
            " best commandline tool clean code\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " important differences mutual funds exchange traded funds etfs\n",
            " etf perform differently holdings\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " credit monitoring services worth monthly fee\n",
            " freeze credit\n",
            "Actual Value:  1.0,  1\n",
            "Incorrect examples:  690\n",
            "Incorrect positive examples:  673\n",
            "incorrect negative examples:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-h4UBzKiam5",
        "colab_type": "code",
        "outputId": "cfde3e7b-15d0-40ac-e5a3-7dfd134a23d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "k=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  if(int(flat_true_labels[i])!=int(test_df.iloc[i,4])):\n",
        "    print(\"Not correct\")  \n",
        "wrpos=0\n",
        "wrneg=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  pred=int(float(flat_predictions[i]))\n",
        "  real=int(float(flat_true_labels[i]))\n",
        "  if(pred!=real):\n",
        "    if(flat_true_labels[i]==1):\n",
        "      wrpos+=1\n",
        "    else:\n",
        "      wrneg+=1  \n",
        "    if(k<=11):\n",
        "      print(\"\\n-----------------------------\\n\",test_df.iloc[i,2]+\"\\n\",test_df.iloc[i,3]+\"\\nActual Value: \",test_df.iloc[i,4]+\", \",flat_true_labels[i])\n",
        "    k+=1\n",
        "print(\"Incorrect examples: \",k) \n",
        "print(\"Incorrect positive examples: \",wrpos)\n",
        "print(\"incorrect negative examples: \",wrneg)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-dd6314647774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_true_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not correct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwrpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0.0'"
          ]
        }
      ]
    }
  ]
}