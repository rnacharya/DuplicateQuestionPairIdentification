{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMUpdate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzKR1F5VczKb",
        "colab_type": "code",
        "outputId": "ffd8d2ef-c09e-4eb8-998e-00f069e7ae07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmFxjwH3c1fP",
        "colab_type": "code",
        "outputId": "1d74cc03-2ada-42d2-f479-bbdce9538874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('shuffledTraining4K.csv')\n",
        "print(train_df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkwtWxfDdCwk",
        "colab_type": "code",
        "outputId": "036bb6a9-a020-46f1-d4ea-0d124a6c89f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "train_df = shuffle(train_df)\n",
        "test_df = train_df[3500:]\n",
        "train_df = train_df[:3500]\n",
        "for q in ['question1', 'question2']:\n",
        "    train_df[q + '_n'] = train_df[q]\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3500, 8)\n",
            "(500, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxwZOV4KdSoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "max_seq_length = 256\n",
        "use_w2v = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88ypISXodWM_",
        "colab_type": "code",
        "outputId": "6c75f584-2aee-4f9f-cf2a-cda995cd0fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from time import time\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from tensorflow.python.keras.layers import Input, Embedding, LSTM, GRU, Conv1D, Conv2D, GlobalMaxPool1D, Dense, Dropout\n",
        "import re\n",
        "\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "import gensim\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import itertools\n",
        "\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    # Pre process and convert texts to a list of words\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def make_w2v_embeddings(df, embedding_dim=300, empty_w2v=False):\n",
        "    vocabs = {}\n",
        "    vocabs_cnt = 0\n",
        "\n",
        "    vocabs_not_w2v = {}\n",
        "    vocabs_not_w2v_cnt = 0\n",
        "\n",
        "    # Stopwords\n",
        "    stops = set(stopwords.words('english'))\n",
        "\n",
        "    # Load word2vec\n",
        "    print(\"Loading word2vec model(it may takes 2-3 mins) ...\")\n",
        "\n",
        "    if empty_w2v:\n",
        "        word2vec = EmptyWord2Vec\n",
        "    else:\n",
        "        word2vec = KeyedVectors.load_word2vec_format(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "        # word2vec = gensim.models.word2vec.Word2Vec.load(\"./data/Quora-Question-Pairs.w2v\").wv\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # print(index)\n",
        "        # Print the number of embedded sentences.\n",
        "        if index != 0 and index % 1000 == 0:\n",
        "            print(\"{:,} sentences embedded.\".format(index), flush=True)\n",
        "\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for question in ['question1', 'question2']:\n",
        "\n",
        "            q2n = []  # q2n -> question numbers representation\n",
        "            for word in text_to_word_list(row[question]):\n",
        "                # Check for unwanted words\n",
        "                if word in stops:\n",
        "                    continue\n",
        "\n",
        "                # If a word is missing from word2vec model.\n",
        "                if word not in word2vec.vocab:\n",
        "                    if word not in vocabs_not_w2v:\n",
        "                        vocabs_not_w2v_cnt += 1\n",
        "                        vocabs_not_w2v[word] = 1\n",
        "\n",
        "                # If you have never seen a word, append it to vocab dictionary.\n",
        "                if word not in vocabs:\n",
        "                    vocabs_cnt += 1\n",
        "                    vocabs[word] = vocabs_cnt\n",
        "                    q2n.append(vocabs_cnt)\n",
        "                else:\n",
        "                    q2n.append(vocabs[word])\n",
        "\n",
        "            # Append question as number representation\n",
        "            df.at[index, question + '_n'] = q2n\n",
        "\n",
        "    embeddings = 1 * np.random.randn(len(vocabs) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "    embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "    # Build the embedding matrix\n",
        "    for word, index in vocabs.items():\n",
        "        if word in word2vec.vocab:\n",
        "            embeddings[index] = word2vec.word_vec(word)\n",
        "    del word2vec\n",
        "\n",
        "    return df, embeddings\n",
        "\n",
        "\n",
        "def split_and_zero_padding(df, max_seq_length):\n",
        "    # Split to dicts\n",
        "    X = {'left': df['question1_n'], 'right': df['question2_n']}\n",
        "\n",
        "    # Zero padding\n",
        "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
        "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "#  --\n",
        "\n",
        "class ManDist(Layer):\n",
        "    \"\"\"\n",
        "    Keras Custom Layer that calculates Manhattan Distance.\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize the layer, No need to include inputs parameter!\n",
        "    def __init__(self, **kwargs):\n",
        "        self.result = None\n",
        "        super(ManDist, self).__init__(**kwargs)\n",
        "\n",
        "    # input_shape will automatic collect input shapes to build layer\n",
        "    def build(self, input_shape):\n",
        "        super(ManDist, self).build(input_shape)\n",
        "\n",
        "    # This is where the layer's logic lives.\n",
        "    def call(self, x, **kwargs):\n",
        "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
        "        return self.result\n",
        "\n",
        "    # return output shape\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return K.int_shape(self.result)\n",
        "\n",
        "\n",
        "class EmptyWord2Vec:\n",
        "    \"\"\"\n",
        "    Just for test use.\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    word_vec = {}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obZAfkqxdePT",
        "colab_type": "code",
        "outputId": "a618ec3e-541d-447c-d038-83ce86a74ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "train_df, embeddings = make_w2v_embeddings(train_df, embedding_dim=embedding_dim, empty_w2v=not use_w2v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word2vec model(it may takes 2-3 mins) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1,000 sentences embedded.\n",
            "3,000 sentences embedded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od3hgamPdhyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_size = int(len(train_df) * 0.1)\n",
        "training_size = len(train_df) - validation_size\n",
        "\n",
        "X = train_df[['question1_n', 'question2_n']]\n",
        "Y = train_df['is_duplicate']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45kfC5fveZCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
        "# X_train = X\n",
        "# Y_train = Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkWjsBEsfrhz",
        "colab_type": "code",
        "outputId": "31d68b7e-4130-42e6-be48-9752e8fb7465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_df = pd.read_csv('drive/My Drive/Colab Notebooks/stackOverflowTestSet.csv')\n",
        "print(validation_df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zt5XEmAf9Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_df = shuffle(validation_df)\n",
        "for q in ['question1', 'question2']:\n",
        "    validation_df[q + '_n'] = validation_df[q]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljYHHJvwgGEm",
        "colab_type": "code",
        "outputId": "62a59bbd-bad9-449f-c26a-ff1d6110bab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "validation_df, valid_embeddings = make_w2v_embeddings(validation_df, embedding_dim=embedding_dim, empty_w2v=not use_w2v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word2vec model(it may takes 2-3 mins) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qU7gURqgu-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_validation = validation_df[['question1_n', 'question2_n']]\n",
        "Y_validation = validation_df['is_duplicate']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgxrxlavgWks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = split_and_zero_padding(X_train, max_seq_length)\n",
        "X_validation = split_and_zero_padding(X_validation, max_seq_length)\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ2I_3kPgequ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpus = 2\n",
        "batch_size = 1024 * gpus\n",
        "n_epoch = 50\n",
        "n_hidden = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6YLinbzggq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Sequential()\n",
        "x.add(Embedding(len(embeddings), embedding_dim,\n",
        "                weights=[embeddings], input_shape=(max_seq_length,), trainable=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG2b-YIXgjeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.add(LSTM(n_hidden))\n",
        "\n",
        "shared_model = x\n",
        "\n",
        "# The visible layer\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ZmvrtDgmv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
        "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g88XvScMgpFV",
        "colab_type": "code",
        "outputId": "62d65dc6-e7e0-42b2-a808-61ad4fc38cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy', 'mean_squared_error'])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "model.summary()\n",
        "shared_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 50)           2450700     input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "man_dist_2 (ManDist)            (None, 1)            0           sequential_2[1][0]               \n",
            "                                                                 sequential_2[2][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,450,700\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 2,380,500\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 256, 300)          2380500   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                70200     \n",
            "=================================================================\n",
            "Total params: 2,450,700\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 2,380,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3ONfFRs1hLq",
        "colab_type": "code",
        "outputId": "36711043-facc-4d18-965a-c40b83dfdab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training_start_time = time()\n",
        "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\n",
        "                           batch_size=batch_size, epochs=n_epoch,\n",
        "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "training_end_time = time()\n",
        "print(\"Training time finished.\\n%d epochs in %12.2f\" % (n_epoch,\n",
        "                                                        training_end_time - training_start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3150 samples, validate on 350 samples\n",
            "Epoch 1/50\n",
            "3150/3150 [==============================] - 25s 8ms/sample - loss: 0.3062 - acc: 0.5737 - f1_m: 0.3088 - precision_m: 0.7977 - recall_m: 0.1915 - val_loss: 0.3314 - val_acc: 0.5429 - val_f1_m: 0.2593 - val_precision_m: 0.7000 - val_recall_m: 0.1591\n",
            "Epoch 2/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2961 - acc: 0.5794 - f1_m: 0.3376 - precision_m: 0.8116 - recall_m: 0.2132 - val_loss: 0.3237 - val_acc: 0.5429 - val_f1_m: 0.2661 - val_precision_m: 0.6905 - val_recall_m: 0.1648\n",
            "Epoch 3/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2867 - acc: 0.5857 - f1_m: 0.3618 - precision_m: 0.8066 - recall_m: 0.2340 - val_loss: 0.3164 - val_acc: 0.5371 - val_f1_m: 0.2703 - val_precision_m: 0.6522 - val_recall_m: 0.1705\n",
            "Epoch 4/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2775 - acc: 0.5968 - f1_m: 0.3797 - precision_m: 0.8121 - recall_m: 0.2478 - val_loss: 0.3094 - val_acc: 0.5429 - val_f1_m: 0.2982 - val_precision_m: 0.6538 - val_recall_m: 0.1932\n",
            "Epoch 5/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.2688 - acc: 0.6044 - f1_m: 0.4170 - precision_m: 0.8181 - recall_m: 0.2802 - val_loss: 0.3027 - val_acc: 0.5571 - val_f1_m: 0.3348 - val_precision_m: 0.6842 - val_recall_m: 0.2216\n",
            "Epoch 6/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2606 - acc: 0.6133 - f1_m: 0.4389 - precision_m: 0.8163 - recall_m: 0.3007 - val_loss: 0.2965 - val_acc: 0.5543 - val_f1_m: 0.3390 - val_precision_m: 0.6667 - val_recall_m: 0.2273\n",
            "Epoch 7/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.2526 - acc: 0.6235 - f1_m: 0.4604 - precision_m: 0.8213 - recall_m: 0.3198 - val_loss: 0.2905 - val_acc: 0.5543 - val_f1_m: 0.3445 - val_precision_m: 0.6613 - val_recall_m: 0.2330\n",
            "Epoch 8/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.2450 - acc: 0.6356 - f1_m: 0.4885 - precision_m: 0.8155 - recall_m: 0.3489 - val_loss: 0.2850 - val_acc: 0.5657 - val_f1_m: 0.3719 - val_precision_m: 0.6818 - val_recall_m: 0.2557\n",
            "Epoch 9/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.2378 - acc: 0.6476 - f1_m: 0.5118 - precision_m: 0.8147 - recall_m: 0.3731 - val_loss: 0.2798 - val_acc: 0.5743 - val_f1_m: 0.3968 - val_precision_m: 0.6901 - val_recall_m: 0.2784\n",
            "Epoch 10/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2310 - acc: 0.6543 - f1_m: 0.5390 - precision_m: 0.8333 - recall_m: 0.3983 - val_loss: 0.2750 - val_acc: 0.5914 - val_f1_m: 0.4348 - val_precision_m: 0.7143 - val_recall_m: 0.3125\n",
            "Epoch 11/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2247 - acc: 0.6622 - f1_m: 0.5548 - precision_m: 0.8210 - recall_m: 0.4193 - val_loss: 0.2707 - val_acc: 0.6029 - val_f1_m: 0.4591 - val_precision_m: 0.7284 - val_recall_m: 0.3352\n",
            "Epoch 12/50\n",
            "3150/3150 [==============================] - 24s 8ms/sample - loss: 0.2187 - acc: 0.6730 - f1_m: 0.5733 - precision_m: 0.8226 - recall_m: 0.4401 - val_loss: 0.2668 - val_acc: 0.6057 - val_f1_m: 0.4692 - val_precision_m: 0.7262 - val_recall_m: 0.3466\n",
            "Epoch 13/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2131 - acc: 0.6860 - f1_m: 0.6059 - precision_m: 0.8320 - recall_m: 0.4766 - val_loss: 0.2632 - val_acc: 0.6171 - val_f1_m: 0.4962 - val_precision_m: 0.7333 - val_recall_m: 0.3750\n",
            "Epoch 14/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2080 - acc: 0.6937 - f1_m: 0.6138 - precision_m: 0.8286 - recall_m: 0.4875 - val_loss: 0.2598 - val_acc: 0.6171 - val_f1_m: 0.5000 - val_precision_m: 0.7283 - val_recall_m: 0.3807\n",
            "Epoch 15/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.2033 - acc: 0.7022 - f1_m: 0.6358 - precision_m: 0.8284 - recall_m: 0.5160 - val_loss: 0.2568 - val_acc: 0.6200 - val_f1_m: 0.5164 - val_precision_m: 0.7172 - val_recall_m: 0.4034\n",
            "Epoch 16/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1989 - acc: 0.7067 - f1_m: 0.6476 - precision_m: 0.8263 - recall_m: 0.5330 - val_loss: 0.2541 - val_acc: 0.6286 - val_f1_m: 0.5324 - val_precision_m: 0.7255 - val_recall_m: 0.4205\n",
            "Epoch 17/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1946 - acc: 0.7159 - f1_m: 0.6551 - precision_m: 0.8263 - recall_m: 0.5427 - val_loss: 0.2517 - val_acc: 0.6343 - val_f1_m: 0.5429 - val_precision_m: 0.7308 - val_recall_m: 0.4318\n",
            "Epoch 18/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1908 - acc: 0.7238 - f1_m: 0.6719 - precision_m: 0.8325 - recall_m: 0.5632 - val_loss: 0.2496 - val_acc: 0.6371 - val_f1_m: 0.5480 - val_precision_m: 0.7333 - val_recall_m: 0.4375\n",
            "Epoch 19/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1873 - acc: 0.7273 - f1_m: 0.6763 - precision_m: 0.8239 - recall_m: 0.5736 - val_loss: 0.2476 - val_acc: 0.6286 - val_f1_m: 0.5455 - val_precision_m: 0.7091 - val_recall_m: 0.4432\n",
            "Epoch 20/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1840 - acc: 0.7371 - f1_m: 0.7020 - precision_m: 0.8284 - recall_m: 0.6098 - val_loss: 0.2459 - val_acc: 0.6286 - val_f1_m: 0.5486 - val_precision_m: 0.7054 - val_recall_m: 0.4489\n",
            "Epoch 21/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1810 - acc: 0.7438 - f1_m: 0.7109 - precision_m: 0.8281 - recall_m: 0.6231 - val_loss: 0.2443 - val_acc: 0.6314 - val_f1_m: 0.5567 - val_precision_m: 0.7043 - val_recall_m: 0.4602\n",
            "Epoch 22/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1780 - acc: 0.7495 - f1_m: 0.7109 - precision_m: 0.8260 - recall_m: 0.6241 - val_loss: 0.2428 - val_acc: 0.6371 - val_f1_m: 0.5666 - val_precision_m: 0.7094 - val_recall_m: 0.4716\n",
            "Epoch 23/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1754 - acc: 0.7571 - f1_m: 0.7276 - precision_m: 0.8276 - recall_m: 0.6496 - val_loss: 0.2415 - val_acc: 0.6429 - val_f1_m: 0.5791 - val_precision_m: 0.7107 - val_recall_m: 0.4886\n",
            "Epoch 24/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1729 - acc: 0.7654 - f1_m: 0.7399 - precision_m: 0.8305 - recall_m: 0.6673 - val_loss: 0.2403 - val_acc: 0.6514 - val_f1_m: 0.5933 - val_precision_m: 0.7177 - val_recall_m: 0.5057\n",
            "Epoch 25/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1705 - acc: 0.7749 - f1_m: 0.7562 - precision_m: 0.8422 - recall_m: 0.6862 - val_loss: 0.2392 - val_acc: 0.6543 - val_f1_m: 0.6007 - val_precision_m: 0.7165 - val_recall_m: 0.5170\n",
            "Epoch 26/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1681 - acc: 0.7819 - f1_m: 0.7616 - precision_m: 0.8401 - recall_m: 0.6966 - val_loss: 0.2383 - val_acc: 0.6543 - val_f1_m: 0.6033 - val_precision_m: 0.7132 - val_recall_m: 0.5227\n",
            "Epoch 27/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1660 - acc: 0.7879 - f1_m: 0.7745 - precision_m: 0.8427 - recall_m: 0.7165 - val_loss: 0.2373 - val_acc: 0.6571 - val_f1_m: 0.6104 - val_precision_m: 0.7121 - val_recall_m: 0.5341\n",
            "Epoch 28/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1639 - acc: 0.7962 - f1_m: 0.7858 - precision_m: 0.8428 - recall_m: 0.7364 - val_loss: 0.2365 - val_acc: 0.6629 - val_f1_m: 0.6194 - val_precision_m: 0.7164 - val_recall_m: 0.5455\n",
            "Epoch 29/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1619 - acc: 0.8019 - f1_m: 0.7929 - precision_m: 0.8446 - recall_m: 0.7475 - val_loss: 0.2359 - val_acc: 0.6657 - val_f1_m: 0.6238 - val_precision_m: 0.7185 - val_recall_m: 0.5511\n",
            "Epoch 30/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1599 - acc: 0.8060 - f1_m: 0.7923 - precision_m: 0.8415 - recall_m: 0.7486 - val_loss: 0.2354 - val_acc: 0.6657 - val_f1_m: 0.6238 - val_precision_m: 0.7185 - val_recall_m: 0.5511\n",
            "Epoch 31/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1581 - acc: 0.8098 - f1_m: 0.8015 - precision_m: 0.8458 - recall_m: 0.7620 - val_loss: 0.2350 - val_acc: 0.6657 - val_f1_m: 0.6238 - val_precision_m: 0.7185 - val_recall_m: 0.5511\n",
            "Epoch 32/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1564 - acc: 0.8146 - f1_m: 0.8041 - precision_m: 0.8494 - recall_m: 0.7635 - val_loss: 0.2344 - val_acc: 0.6629 - val_f1_m: 0.6218 - val_precision_m: 0.7132 - val_recall_m: 0.5511\n",
            "Epoch 33/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1546 - acc: 0.8171 - f1_m: 0.8086 - precision_m: 0.8505 - recall_m: 0.7708 - val_loss: 0.2338 - val_acc: 0.6686 - val_f1_m: 0.6282 - val_precision_m: 0.7206 - val_recall_m: 0.5568\n",
            "Epoch 34/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1529 - acc: 0.8235 - f1_m: 0.8182 - precision_m: 0.8498 - recall_m: 0.7890 - val_loss: 0.2334 - val_acc: 0.6686 - val_f1_m: 0.6282 - val_precision_m: 0.7206 - val_recall_m: 0.5568\n",
            "Epoch 35/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1512 - acc: 0.8254 - f1_m: 0.8175 - precision_m: 0.8531 - recall_m: 0.7850 - val_loss: 0.2332 - val_acc: 0.6657 - val_f1_m: 0.6262 - val_precision_m: 0.7153 - val_recall_m: 0.5568\n",
            "Epoch 36/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1497 - acc: 0.8305 - f1_m: 0.8241 - precision_m: 0.8556 - recall_m: 0.7949 - val_loss: 0.2327 - val_acc: 0.6657 - val_f1_m: 0.6262 - val_precision_m: 0.7153 - val_recall_m: 0.5568\n",
            "Epoch 37/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1481 - acc: 0.8365 - f1_m: 0.8341 - precision_m: 0.8588 - recall_m: 0.8109 - val_loss: 0.2321 - val_acc: 0.6686 - val_f1_m: 0.6306 - val_precision_m: 0.7174 - val_recall_m: 0.5625\n",
            "Epoch 38/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1466 - acc: 0.8403 - f1_m: 0.8365 - precision_m: 0.8602 - recall_m: 0.8142 - val_loss: 0.2315 - val_acc: 0.6657 - val_f1_m: 0.6262 - val_precision_m: 0.7153 - val_recall_m: 0.5568\n",
            "Epoch 39/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1451 - acc: 0.8432 - f1_m: 0.8427 - precision_m: 0.8663 - recall_m: 0.8203 - val_loss: 0.2314 - val_acc: 0.6657 - val_f1_m: 0.6286 - val_precision_m: 0.7122 - val_recall_m: 0.5625\n",
            "Epoch 40/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1437 - acc: 0.8448 - f1_m: 0.8404 - precision_m: 0.8639 - recall_m: 0.8181 - val_loss: 0.2312 - val_acc: 0.6629 - val_f1_m: 0.6242 - val_precision_m: 0.7101 - val_recall_m: 0.5568\n",
            "Epoch 41/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1423 - acc: 0.8476 - f1_m: 0.8477 - precision_m: 0.8652 - recall_m: 0.8314 - val_loss: 0.2308 - val_acc: 0.6600 - val_f1_m: 0.6198 - val_precision_m: 0.7080 - val_recall_m: 0.5511\n",
            "Epoch 42/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1409 - acc: 0.8530 - f1_m: 0.8459 - precision_m: 0.8691 - recall_m: 0.8246 - val_loss: 0.2304 - val_acc: 0.6571 - val_f1_m: 0.6154 - val_precision_m: 0.7059 - val_recall_m: 0.5455\n",
            "Epoch 43/50\n",
            "3150/3150 [==============================] - 22s 7ms/sample - loss: 0.1396 - acc: 0.8552 - f1_m: 0.8508 - precision_m: 0.8697 - recall_m: 0.8327 - val_loss: 0.2302 - val_acc: 0.6571 - val_f1_m: 0.6154 - val_precision_m: 0.7059 - val_recall_m: 0.5455\n",
            "Epoch 44/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1383 - acc: 0.8590 - f1_m: 0.8626 - precision_m: 0.8761 - recall_m: 0.8496 - val_loss: 0.2297 - val_acc: 0.6571 - val_f1_m: 0.6154 - val_precision_m: 0.7059 - val_recall_m: 0.5455\n",
            "Epoch 45/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1371 - acc: 0.8606 - f1_m: 0.8552 - precision_m: 0.8687 - recall_m: 0.8421 - val_loss: 0.2295 - val_acc: 0.6600 - val_f1_m: 0.6174 - val_precision_m: 0.7111 - val_recall_m: 0.5455\n",
            "Epoch 46/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1358 - acc: 0.8641 - f1_m: 0.8635 - precision_m: 0.8763 - recall_m: 0.8511 - val_loss: 0.2291 - val_acc: 0.6629 - val_f1_m: 0.6218 - val_precision_m: 0.7132 - val_recall_m: 0.5511\n",
            "Epoch 47/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1347 - acc: 0.8683 - f1_m: 0.8656 - precision_m: 0.8705 - recall_m: 0.8613 - val_loss: 0.2288 - val_acc: 0.6629 - val_f1_m: 0.6194 - val_precision_m: 0.7164 - val_recall_m: 0.5455\n",
            "Epoch 48/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1335 - acc: 0.8702 - f1_m: 0.8657 - precision_m: 0.8776 - recall_m: 0.8544 - val_loss: 0.2287 - val_acc: 0.6629 - val_f1_m: 0.6194 - val_precision_m: 0.7164 - val_recall_m: 0.5455\n",
            "Epoch 49/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1323 - acc: 0.8727 - f1_m: 0.8723 - precision_m: 0.8791 - recall_m: 0.8655 - val_loss: 0.2285 - val_acc: 0.6629 - val_f1_m: 0.6194 - val_precision_m: 0.7164 - val_recall_m: 0.5455\n",
            "Epoch 50/50\n",
            "3150/3150 [==============================] - 23s 7ms/sample - loss: 0.1312 - acc: 0.8756 - f1_m: 0.8756 - precision_m: 0.8823 - recall_m: 0.8691 - val_loss: 0.2281 - val_acc: 0.6657 - val_f1_m: 0.6238 - val_precision_m: 0.7185 - val_recall_m: 0.5511\n",
            "Training time finished.\n",
            "50 epochs in      1133.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDWFxCT52zOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm.final1')\n",
        "model_file = drive.CreateFile({'title' : 'lstm.final1'})\n",
        "model_file.SetContentFile('lstm.final1')\n",
        "model_file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShgEWVTx95aM",
        "colab_type": "code",
        "outputId": "a0dae63e-efc5-4ca7-d029-a925e08d8e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print('success!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jStuZsg698Md",
        "colab_type": "code",
        "outputId": "cbd35283-7c27-4082-ea0c-30043e3b743c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1JPVP08X8DbhQj33PdhEDKuYsVcI2rPHe'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP1z4Zo0-Rcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(malstm_trained.history['mean_squared_error'])\n",
        "# plt.plot(malstm_trained.history['accuracy'])\n",
        "\n",
        "# plt.plot(malstm_trained.history['mean_absolute_error'])\n",
        "# plt.plot(malstm_trained.history['mean_absolute_percentage_error'])\n",
        "# plt.plot(malstm_trained.history['cosine_proximity'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rg3W5XP-hU-",
        "colab_type": "code",
        "outputId": "cdf6c66e-fc17-4c59-f05b-1350eb5badd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.plot(malstm_trained.history['acc'])\n",
        "plt.plot(malstm_trained.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "# plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(212)\n",
        "plt.plot(malstm_trained.history['loss'])\n",
        "plt.plot(malstm_trained.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.tight_layout(h_pad=1.0)\n",
        "# plt.show()\n",
        "plt.savefig('final1.png')\n",
        "print(str(malstm_trained.history['val_acc'][-1])[:6] +\n",
        "      \"(max: \" + str(max(malstm_trained.history['val_acc']))[:6] + \")\")\n",
        "print(\"Done.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6657(max: 0.6685)\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrCtSKAD_AL6",
        "colab_type": "code",
        "outputId": "f9f84da8-249f-4797-9a2c-ebfd238e696b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test_df = pd.read_csv('drive/My Drive/stackOverflowFinal.csv')\n",
        "# test_df = pd.read_csv('drive/My Drive/Colab Notebooks/stackOverflowTestSet.csv')\n",
        "test_df = pd.read_csv('shuffledTraining4K.csv')\n",
        "test_df = train_df[3500:]\n",
        "print(test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYNfUZwmRbAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for q in ['question1', 'question2']:\n",
        "    test_df[q + '_n'] = test_df[q]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdDY2TROuzzS",
        "colab_type": "code",
        "outputId": "9db0c766-cf04-4a90-c04a-e1e8825bb68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(test_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id  ...                                        question2_n\n",
            "2737   296  ...  How do concentric and eccentric contraction co...\n",
            "3336  2847  ...  What is the best farewell sample letter from a...\n",
            "3925  2451  ...  Why do we often judge people by their appearance?\n",
            "906    502  ...                         Is World War III imminent?\n",
            "590   2573  ...  What are the biggest blunders in the history o...\n",
            "...    ...  ...                                                ...\n",
            "2692  5230  ...  What are macromolecules, and what are some exa...\n",
            "2402  2430  ...  How can I move to Canada legally with a studen...\n",
            "1756  2812  ...  Which is the best and worst bank in India to o...\n",
            "412    880  ...  Do we have telescopes powerful enough nowadays...\n",
            "2121  1406  ...               How do I get rid of severe dandruff?\n",
            "\n",
            "[500 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIJVSX7rTNrn",
        "colab_type": "code",
        "outputId": "33beb06d-03ec-4561-f3a7-0e316c091e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "test_df, test_embeddings = make_w2v_embeddings(test_df, embedding_dim=embedding_dim, empty_w2v=not use_w2v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word2vec model(it may takes 2-3 mins) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2,000 sentences embedded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXOXBH4NTRpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X = test_df[['question1_n', 'question2_n']]\n",
        "test_Y = test_df['is_duplicate']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4G3BvE9V1NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X = split_and_zero_padding(test_X, max_seq_length)\n",
        "test_Y = test_Y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3IJoTJsU4br",
        "colab_type": "code",
        "outputId": "57cafd37-f4b2-4b5a-beff-07b53893ce63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(test_X)\n",
        "# print(test_Y)\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# loss, accuracy, f1_score, precision, recall = model.evaluate([test_X['left'], test_X['right']], test_Y, verbose=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2kSzF-WViXG",
        "colab_type": "code",
        "outputId": "4afc2587-8f37-495f-c486-227be8d1882b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Loss: \", loss)\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"f1_score: \", f1_score)\n",
        "print(\"precision: \", precision)\n",
        "print(\"recall: \", recall)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.3521001856649915\n",
            "accuracy:  0.5143333\n",
            "f1_score:  0.026159678\n",
            "precision:  0.25531915\n",
            "recall:  0.013962766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOouCSgmfcfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict([test_X['left'], test_X['right']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iayQK4QlhRiE",
        "colab_type": "code",
        "outputId": "65d75d08-427f-4795-d845-7039557ae098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "correct = 0;\n",
        "wrong = 0;\n",
        "correctPrint = 0;\n",
        "wrongPrint = 0;\n",
        "for i in range(0, len(prediction)):\n",
        "    if prediction[i] > 0.5:\n",
        "      similarity = 1\n",
        "    else:\n",
        "      similarity = 0\n",
        "    if similarity == test_Y[i]:\n",
        "      if (correctPrint < 10 and similarity == 1):\n",
        "        print(\"Correct\")\n",
        "        print(\"Sentence 1: \", test_df['question1'][i])\n",
        "        print(\"Sentence 2: \", test_df['question2'][i])\n",
        "        print(\"Predicted: \", similarity);\n",
        "        print(\"Correct: \", test_Y[i]);\n",
        "        correctPrint = correctPrint + 1\n",
        "      correct = correct + 1;\n",
        "    else:\n",
        "      if (wrongPrint < 10):\n",
        "        print(\"Wrong\")\n",
        "        print(\"Sentence 1: \", test_df['question1'][i])\n",
        "        print(\"Sentence 2: \", test_df['question2'][i])\n",
        "        print(\"Predicted: \", similarity);\n",
        "        print(\"Correct: \", test_Y[i]);\n",
        "        wrongPrint = wrongPrint + 1\n",
        "      wrong = wrong + 1;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong\n",
            "Sentence 1:  What are the differences between a \"traditional\" IRA and a Roth IRA?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  Should I put money in both a ROTH and Traditional IRA?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  Pros, cons, & differences in investing in 401k vs. IRA?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  What is the difference between a Rollover IRA and a Roth IRA?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  18 year old making $60k a year; how should I invest? Traditional or Roth IRA?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  What are the pros/cons of Roth IRA Rollover from a traditional IRA vs. from an after-tax 401(k)?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  Should I open an RRSP if I don't plan to retire in Canada?\n",
            "Sentence 2:  Tax on money withdrawn from Roth 401(k) and Roth IRA when living outside the United States and over 59.5-year-old\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  I've often heard of the \"snowball\" method for paying off credit card debt. How does it work?\n",
            "Sentence 2:  Why would anyone want to pay off their debts in a way other than \"highest interest\" first?\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  Student Loan Repayment\n",
            "Sentence 2:  Why would anyone want to pay off their debts in a way other than \"highest interest\" first?\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Wrong\n",
            "Sentence 1:  3 loans under my name, 2 are fixed, one is a declining balance interest loan. Which to pay first?\n",
            "Sentence 2:  Why would anyone want to pay off their debts in a way other than \"highest interest\" first?\n",
            "Predicted:  0\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  How much is college / university projected to cost in the U.S. in 18 years?\n",
            "Sentence 2:  How much is university projected to cost in Canada in 18 years?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  What are \"preferred\" stocks? How are they different from normal (common) stocks?\n",
            "Sentence 2:  Where can I buy preferred stocks as opposed to common stocks?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  UK income tax & charitable donations: How much is income tax reduced by donations?\n",
            "Sentence 2:  Canadian income tax & charitable donations: How much is income tax reduced by donations?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Received email from credit card company: \"URGENT: Your Master Card SecureCode Password has expired!\" Is it legitimate?\n",
            "Sentence 2:  I received an email from my credit card company titled \"URGENT: Your VbV VISA Password has expired!\" Is it legitimate?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Can business in Australia charge a transaction fee for using a credit card?\n",
            "Sentence 2:  Can a merchant charge you more in the US if you want to use a credit card?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Importance of liquidity in emergency fund?\n",
            "Sentence 2:  Where should I park my rainy-day / emergency fund?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Deciding between Pre-Tax 401(k) and Roth 401(k)\n",
            "Sentence 2:  Recent graduate with new job: Choose Roth 401(k), or traditional 401(k)?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Deciding between Pre-Tax 401(k) and Roth 401(k)\n",
            "Sentence 2:  What factors should I take into account when deciding how much of my 401(k) contribution should go into my Roth 401(k)?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Deciding between Pre-Tax 401(k) and Roth 401(k)\n",
            "Sentence 2:  What factors should I take into account when deciding how much of my 401(k) contribution should go into my Roth 401(k)?\n",
            "Predicted:  1\n",
            "Correct:  1\n",
            "Correct\n",
            "Sentence 1:  Do large market players using HFT make it unsafe for individual investors to be in the stock market?\n",
            "Sentence 2:  Is it wise to invest money in the stock market?\n",
            "Predicted:  1\n",
            "Correct:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31wNhU2Gib9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samp = \"\"\"donald trump will be on the ballot in california as the nominee of the republican party and the american independent party. \n",
        "so is trump elected as a republican president or this particular party\\'s president. why can a candidate be on the ballot for 2 parties. \n",
        "\n",
        "\n",
        "why is this possible.  aren\\'t there laws regarding this\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aow5PXw8AduI",
        "colab_type": "code",
        "outputId": "71de6eee-1311-4863-ae45-387e25e68528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(samp.replace(\"\\r\",\"\").replace(\"\\n\",\"\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "donald trump will be on the ballot in california as the nominee of the republican party and the american independent party. so is trump elected as a republican president or this particular party's president. why can a candidate be on the ballot for 2 parties. why is this possible.  aren't there laws regarding this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-2vrVoAC0xy",
        "colab_type": "code",
        "outputId": "0a67adf9-4904-4731-814f-c29c9774b51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "# prediction = model.predict([\"What is the story of Kohinoor (Koh-i-Noor) Diamond?\", \"What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e775f13c0eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"What is the story of Kohinoor (Koh-i-Noor) Diamond?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    515\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     data = [\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     ]\n\u001b[1;32m    519\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    515\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     data = [\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     ]\n\u001b[1;32m    519\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x, expected_shape)\u001b[0m\n\u001b[1;32m    440\u001b[0m         'Expected an array data type but received an integer: {}'.format(x))\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m   if (x.shape is not None and len(x.shape) == 1 and\n\u001b[0m\u001b[1;32m    443\u001b[0m       (expected_shape is None or len(expected_shape) != 1)):\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EigdcA5zuEMk",
        "colab_type": "code",
        "outputId": "d5e26d99-3c5b-4149-8e25-c92b1d007f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(test_X['left'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...    3    4    3]\n",
            " [   0    0    0 ...    4    2    3]\n",
            " [   0    0    0 ...   23   24    3]\n",
            " ...\n",
            " [   0    0    0 ... 4817 5400  372]\n",
            " [   0    0    0 ...   34 4612  532]\n",
            " [   0    0    0 ... 1474 5773 4085]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3vMJFZIuL7e",
        "colab_type": "code",
        "outputId": "2ad31aaf-2812-4c1b-d54e-785cad6e1d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "example_test = pd.read_csv('drive/My Drive/Colab Notebooks/exampleTest.csv')\n",
        "for q in ['question1', 'question2']:\n",
        "    example_test[q + '_n'] = example_test[q]\n",
        "\n",
        "print(example_test)\n",
        "example_test, example_test_embeddings = make_w2v_embeddings(example_test, embedding_dim=embedding_dim, empty_w2v=not use_w2v)\n",
        "example_test_X = example_test[['question1_n', 'question2_n']]\n",
        "example_test_X = split_and_zero_padding(example_test_X, max_seq_length)\n",
        "prediction = model.predict([example_test_X['left'], example_test_X['right']])\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  ...                                        question2_n\n",
            "0   1  ...  What would happen if the Indian government sto...\n",
            "\n",
            "[1 rows x 8 columns]\n",
            "Loading word2vec model(it may takes 2-3 mins) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.5993961]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9KDrbwpulTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}