{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT+Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Z4FEUggBQz",
        "colab_type": "code",
        "outputId": "783aa39c-e5c6-44f9-a9b3-ddaf158ec730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(\"My GPU Name is: \",gpu.name)\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " \n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=19198b33547eea56835a030579a59c7276e9d30e0bf2e9dbd15b58fe614f501b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "My GPU Name is:  Tesla P100-PCIE-16GB\n",
            "Gen RAM Free: 26.4 GB  | Proc size: 155.9 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaZLqI1LgEPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfYlh4FIpsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePIaLYKFIvRr",
        "colab_type": "code",
        "outputId": "dae7aacc-bea5-4e72-d2d0-0f5207c921d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# do I have GPU:\n",
        "gpu_available = torch.cuda.is_available()\n",
        "print(gpu_available)\n",
        "device = torch.device(\"cuda\" if gpu_available else \"cpu\")\n",
        "# number of GPUs I have:\n",
        "num = torch.cuda.device_count()\n",
        "print(f'I have {num} GPUs')\n",
        "\n",
        "# current device index\n",
        "idx = torch.cuda.current_device()\n",
        "print(f'My current device has index {idx}')\n",
        "\n",
        "# GPU's name\n",
        "name = torch.cuda.get_device_name(idx)\n",
        "print(f'My GPU is {name}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "I have 1 GPUs\n",
            "My current device has index 0\n",
            "My GPU is Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHSioiTkIzGb",
        "colab_type": "code",
        "outputId": "03276bdb-659b-48f2-a2e0-089315921762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/08/4a6768ca1a7a4fa37e5ee08077c5d02b8d83876bd36caa5fc24d98992ac2/transformers-2.2.2-py3-none-any.whl (387kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 2.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0e/84041e5245d0bfc0f6c6431b36f8d7e1668ee0ce5f8184e0e1f9ee1082b6/regex-2019.12.19-cp36-cp36m-manylinux2010_x86_64.whl (689kB)\n",
            "\u001b[K     |████████████████████████████████| 696kB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.36)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.36)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=241c64835e56d8a4c41275cd0c7c29b1563e48a5b14b3001b10e4fe894179ef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, regex, sacremoses, transformers\n",
            "Successfully installed regex-2019.12.19 sacremoses-0.0.35 sentencepiece-0.1.85 transformers-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJZ8jOIjI4ca",
        "colab_type": "code",
        "outputId": "69ef688d-ecc4-405b-b9cc-cb39075fcdd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from pytorch_pretrained_bert import BertAdam\n",
        "#from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mkcVROrCQhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-4pe4VI6v5",
        "colab_type": "code",
        "outputId": "7a32f6d7-ab6f-40cd-982b-3d59dffa5460",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2ececb5-f719-4e49-973b-bcf0957f7869\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b2ececb5-f719-4e49-973b-bcf0957f7869\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJFzsuwt_9v",
        "colab_type": "code",
        "outputId": "c43a40d7-fe0c-4869-be6f-4d9bc06b2d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlSLbYR7aJCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def balancedf(df, size):\n",
        "  size=int(size/2)\n",
        "  df['is_duplicate']=pd.to_numeric(df['is_duplicate'], errors='coerce')\n",
        "  df.dropna(inplace=True)\n",
        "  so_pos=df.loc[df['is_duplicate'] == 1]\n",
        "  so_neg=df.loc[df['is_duplicate'] == 0]\n",
        "  so_pos=so_pos.head(size)\n",
        "  so_neg=so_neg.head(size)\n",
        "  #print(\"Positive: \", so_pos.shape)\n",
        "  #print(\"Negative: \", so_neg.shape)\n",
        "  df=pd.concat([so_pos, so_neg])\n",
        "  #df=df.sample(frac=1)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sodFlhpQI82V",
        "colab_type": "code",
        "outputId": "d690acff-a61c-4c5a-bcd1-bbe2954759f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "quora_df = pd.read_csv(\"drive/My Drive/Colab Notebooks/train.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "#1. quora_df=balancedf(quora_df, 32000)\n",
        "#4. Only quora, in domain\n",
        "quora_df=balancedf(quora_df, 7000)\n",
        "q_pos=quora_df.loc[quora_df['is_duplicate']==1]\n",
        "q_neg=quora_df.loc[quora_df['is_duplicate']==0]\n",
        "print(\"Positive examples:\", q_pos.shape)\n",
        "print(\"Negative examples:\", q_neg.shape)\n",
        "q_train=pd.concat([q_pos.head(3000), au_neg.head(3000)])\n",
        "q_test=pd.concat([q_pos.tail(500), au_neg.tail(500)])\n",
        "df=q_train\n",
        "test_df=q_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "so_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/stackoverflow1-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "#1. so_df=balancedf(so_df, 4000)\n",
        "so_df=balancedf(so_df, 3000)\n",
        "#3 Cross domain, but related genresso_df=balancedf(so_df, 6000)\n",
        "\n",
        "au_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/askubuntu-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "#1,2 \n",
        "au_df=balancedf(au_df, 4000)\n",
        "#3 Cross domain, but related genresau_df=balancedf(au_df, 1000)\n",
        "\n",
        "po_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/politics-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "po_df=balancedf(po_df, 1000)\n",
        "\n",
        "mo_df=pd.read_csv(\"drive/My Drive/Colab Notebooks/money-title_only.csv\", names=['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'])\n",
        "mo_df=balancedf(mo_df, 1000)\n",
        "\n",
        "'''1. All MIX:df=pd.concat([au_df,quora_df])\n",
        "df=df.sample(frac=1)\n",
        "test_df=pd.concat([so_df,po_df,mo_df])\n",
        "test_df=test_df.sample(frac=1)\n",
        "print(df.shape)\n",
        "print(test_df.shape)'''\n",
        "\n",
        "#3. Cross domain but related genres\n",
        "'''df=so_df\n",
        "df=df.sample(frac=1)\n",
        "test_df=au_df\n",
        "test_df=test_df.sample(frac=1)\n",
        "print(df.shape)\n",
        "print(test_df.shape)'''\n",
        "\n",
        "\n",
        "#2. Joint training but related genres mic: \n",
        "'''au_pos=au_df.loc[au_df['is_duplicate'] == 1]\n",
        "au_neg=au_df.loc[au_df['is_duplicate'] == 0]\n",
        "au_train=pd.concat([au_pos.head(1500), au_neg.head(1500)])\n",
        "au_test=pd.concat([au_pos.tail(500), au_neg.tail(500)])\n",
        "df=pd.concat([au_train,so_df])\n",
        "df=df.sample(frac=1)\n",
        "\n",
        "test_df=pd.concat([au_test])\n",
        "test_df=test_df.sample(frac=1)\n",
        "print(df.shape)\n",
        "print(test_df.shape)'''\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(df.shape)\n",
        "print(test_df.shape)\n",
        "\n",
        "df['question1']=df['question1'].astype(str)\n",
        "df['question2']=df['question2'].astype(str)\n",
        "df['is_duplicate']=df['is_duplicate'].astype(str)\n",
        "test_df['question1']=test_df['question1'].astype(str)\n",
        "test_df['question2']=test_df['question2'].astype(str)\n",
        "test_df['is_duplicate']=test_df['is_duplicate'].astype(str)\n",
        "dtypeCount =[df.iloc[:,i].apply(type).value_counts() for i in range(df.shape[1])]\n",
        "print(dtypeCount)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Positive examples: (3500, 5)\n",
            "Negative examples: (3500, 5)\n",
            "Shapes:\n",
            "(5000, 5)\n",
            "(1000, 5)\n",
            "[<class 'str'>    5000\n",
            "Name: qid1, dtype: int64, <class 'str'>    5000\n",
            "Name: qid2, dtype: int64, <class 'str'>    5000\n",
            "Name: question1, dtype: int64, <class 'str'>    5000\n",
            "Name: question2, dtype: int64, <class 'str'>    5000\n",
            "Name: is_duplicate, dtype: int64]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPuOdK8QlGA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessdf(df):\n",
        "  numrows,numcols=df.shape\n",
        "  numrows*=2\n",
        "  sumlen=0\n",
        "  vocab=set()\n",
        "  num_duplicates=0\n",
        "  df['question1']=df['question1'].str.lower()\n",
        "  df['question1']=df['question1'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "  df['question1']=df['question1'].str.replace('[^\\w\\s]','')\n",
        "  df['question2']=df['question2'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "  df['question2']=df['question2'].str.replace('[^\\w\\s]','')\n",
        "  df['question2']=df['question2'].str.lower()\n",
        "  for idx, row in df.iterrows():\n",
        "  #print(row)\n",
        "    q1=row[\"question1\"]\n",
        "    if(q1==\"question1\"):\n",
        "      continue\n",
        "    q2=row[\"question2\"]\n",
        "  #print(q1)\n",
        "  #print(q2)\n",
        "    if(int(float(row[\"is_duplicate\"]))==1):\n",
        "      num_duplicates+=1\n",
        "    sumlen+=len(str(q1))\n",
        "    sumlen+=len(str(q2))\n",
        "    if(\"float\" in str(type(q1)) or \"float\" in str(type(q2))):\n",
        "      continue\n",
        "    vocab.update(q1.split())\n",
        "    vocab.update(q2.split())\n",
        "  print(\"Size of vocabulary:\", len(vocab))  \n",
        "  print(\"Average sequence length: \", int(sumlen/numrows)) \n",
        "  print(\"Number of duplicate questions: \", num_duplicates) \n",
        "#print(df[\"question2\"][1]) \n",
        "  return df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gocXkNlg5p",
        "colab_type": "code",
        "outputId": "782f97f6-cb7b-47e8-f341-a7867d327b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "df=preprocessdf(df)\n",
        "print(df.shape)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary: 7419\n",
            "Average sequence length:  35\n",
            "Number of duplicate questions:  3000\n",
            "(5000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrz_wQa-I_Jq",
        "colab_type": "code",
        "outputId": "fe166bd3-795f-4d8a-8869-6cfe61df2515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Create sentence and label lists\n",
        "text_a = df.question1\n",
        "text_b=df.question2\n",
        "is_dup=df.is_duplicate\n",
        "questions=[]\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "labels=list()\n",
        "m,n=df.shape\n",
        "print(m)\n",
        "for w in range(0, m):\n",
        "  q1=df.iloc[w,2]\n",
        "  #print(q1)\n",
        "  q2=df.iloc[w,3]\n",
        "  #print(q2)\n",
        "  is_d=int(float(df.iloc[w,4]))\n",
        "  #print(is_d)\n",
        "  if(q1==\"question1\"):\n",
        "    continue\n",
        "  questions.append(\"[CLS] \" + str(q1) + \" [SEP] \" +str(q2)+ \" [SEP]\")\n",
        "  #print(is_d)\n",
        "  labels.append(is_d)\n",
        "#labels = df.is_duplicate.values\n",
        "#labels=list(map(int, labels)) \n",
        "labels=np.asarray(labels)\n",
        "print(len(labels))\n",
        "#print(questions[1])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb67l2HsJDy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 80\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZoheTzWJBzM",
        "colab_type": "code",
        "outputId": "a8e02ca3-144b-47b9-fbde-cd271c78833f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "input_ids = [tokenizer.encode(sent) for sent in questions]\n",
        "print (\"Tokenize the first sentence:\")\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_SN8bm2JJNE",
        "colab_type": "code",
        "outputId": "a5a4d689-e20d-40e3-8f4c-79116e6b7006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#print(tokenized_texts[0])\n",
        "##input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "#print(input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 5328, 7221, 3156, 6694, 21766, 28084, 3964, 2634, 102, 2339, 2231, 9225, 21029, 3156, 21766, 28084, 2015, 6694, 21766, 28084, 2015, 9598, 3964, 2634, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_iCD0uEJNJd",
        "colab_type": "code",
        "outputId": "37563ac9-857b-4956-ce12-3eebc85deb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "print(input_ids.shape)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYQRss27JN3V",
        "colab_type": "code",
        "outputId": "f6e6fba2-74f1-4a23-aab2-f8ce6488efc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  att_mask = [int(token_id > 0) for token_id in seq]\n",
        "  attention_masks.append(att_mask)\n",
        "  #print(seq_mask)\n",
        "  #print(seq)\n",
        "  #break\n",
        "#print(attention_masks[0]) \n",
        "print(input_ids[0]) \n",
        "print(attention_masks[0])"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101   101  2350  2458 10381 12707  7315 13484   102  2029  2350  2458\n",
            " 10381 12707  7315 13484   102   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5cQZCPTJU3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvJbL9J-JXUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5zCHaD4JZf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LebX2rBxJb_M",
        "colab_type": "code",
        "outputId": "2bdc71a5-12a6-412c-97d0-7993d50a0cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHh8sIKJhl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfw-eSYdOGCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unfreeze_bert_encoder():\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "048N-B0AJj9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ppI-kTJmIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import tensorflow as tf\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    print(labels)\n",
        "    print(pred_flat)\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    return accuracy_score(labels_flat, pred_flat)#tf.metrics.accuracy(labels=tf.argmax(labels_flat, 1),predictions=pred_flat)#accuracy_score(labels_flat, pred_flat)\n",
        "def flat_precision(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    p=precision_score(labels_flat, pred_flat)\n",
        "    \n",
        "    return p\n",
        "\n",
        "\n",
        "def flat_recall(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(labels_flat)\n",
        "    print(pred_flat)\n",
        "    r=recall_score(labels_flat, pred_flat)\n",
        "    \n",
        "    return r        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv78pkRItqC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#train_epochs=list()\n",
        "train_loss=list()\n",
        "#train_accuracy=list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxBN1wIGVCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcVSZ9gTJoWK",
        "colab_type": "code",
        "outputId": "8375f423-198e-47b7-e3cd-65b321d178f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "model.zero_grad()\n",
        "#unfreeze_bert_encoder()\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "        \n",
        "    # This training code is based on the `run_glue.py` script here:\n",
        "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Put the model into training mode.    \n",
        "        model.train()\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "                \n",
        "        # Forward pass (evaluate the model on this training batch)\n",
        "        # `model` is of type: pytorch_pretrained_bert.modeling.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the loss. `loss` is a Tensor containing a single value; \n",
        "        # the `.item()` function just returns the Python value from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        model.zero_grad()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            # Forward pass, calculate logit predictions\n",
        "            # token_type_ids is for the segment ids, but we only have a single sentence here.\n",
        "            # See https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L258 \n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")  "
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:14.\n",
            "  Batch   120  of    282.    Elapsed: 0:00:20.\n",
            "  Batch   160  of    282.    Elapsed: 0:00:27.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:34.\n",
            "  Batch   240  of    282.    Elapsed: 0:00:40.\n",
            "  Batch   280  of    282.    Elapsed: 0:00:47.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0]\n",
            "[0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0]\n",
            "[0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
            "[0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1]\n",
            "[1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1]\n",
            "[1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0]\n",
            "[1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0]\n",
            "[0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1]\n",
            "[0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1]\n",
            "[1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1]\n",
            "[1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1]\n",
            "[0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0]\n",
            "[0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0]\n",
            "[1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1]\n",
            "[1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1]\n",
            "[1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0]\n",
            "[1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0]\n",
            "[1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0]\n",
            "[1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0]\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1]\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1]\n",
            "[1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0]\n",
            "[1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0]\n",
            "[0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0]\n",
            "[1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0]\n",
            "[0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1]\n",
            "[0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1]\n",
            "[1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0]\n",
            "[1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0]\n",
            "[0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1]\n",
            "[0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1]\n",
            "[1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1]\n",
            "[1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1]\n",
            "[1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1]\n",
            "[1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1]\n",
            "[0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0]\n",
            "[0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0]\n",
            "[0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0]\n",
            "[0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0]\n",
            "[0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1]\n",
            "[0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1]\n",
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "[0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1]\n",
            "[0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1]\n",
            "[1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1]\n",
            "[0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0]\n",
            "[0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0]\n",
            "[1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1]\n",
            "[1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1]\n",
            "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1]\n",
            "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1]\n",
            "[0 0 1 0]\n",
            "[0 0 1 0]\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    282.    Elapsed: 0:00:20.\n",
            "  Batch   160  of    282.    Elapsed: 0:00:27.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:33.\n",
            "  Batch   240  of    282.    Elapsed: 0:00:40.\n",
            "  Batch   280  of    282.    Elapsed: 0:00:47.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:00:47\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0]\n",
            "[0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0]\n",
            "[0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
            "[0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1]\n",
            "[1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1]\n",
            "[1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0]\n",
            "[1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0]\n",
            "[0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1]\n",
            "[0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1]\n",
            "[1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1]\n",
            "[1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1]\n",
            "[0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0]\n",
            "[0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0]\n",
            "[1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1]\n",
            "[1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1]\n",
            "[1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0]\n",
            "[1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0]\n",
            "[1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0]\n",
            "[1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0]\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1]\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1]\n",
            "[1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0]\n",
            "[1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0]\n",
            "[0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0]\n",
            "[1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0]\n",
            "[0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1]\n",
            "[0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1]\n",
            "[1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0]\n",
            "[1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0]\n",
            "[1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0]\n",
            "[0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1]\n",
            "[0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1]\n",
            "[1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1]\n",
            "[1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1]\n",
            "[1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1]\n",
            "[1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1]\n",
            "[0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0]\n",
            "[0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0]\n",
            "[0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0]\n",
            "[0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0]\n",
            "[0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1]\n",
            "[0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1]\n",
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0]\n",
            "[0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1]\n",
            "[0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1]\n",
            "[1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1]\n",
            "[0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0]\n",
            "[0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0]\n",
            "[1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1]\n",
            "[1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1]\n",
            "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1]\n",
            "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1]\n",
            "[0 0 1 0]\n",
            "[0 0 1 0]\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODSWJk7OvfGZ",
        "colab_type": "code",
        "outputId": "83b5c250-c983-4bb0-df49-de5f526a033d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDTk3GaQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1OL2pKp_fbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'classifier-justQuora-nofinetune-balanced.pt'\n",
        "path = F\"drive/My Drive/Colab Notebooks/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvIWUtgwot4Y",
        "colab_type": "code",
        "outputId": "d239699f-b68d-4889-e37d-62a7145abf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "test_df['question1']=test_df['question1'].astype(str)\n",
        "test_df['question2']=test_df['question2'].astype(str)\n",
        "test_df['is_duplicate']=test_df['is_duplicate'].astype(str)\n",
        "test_df=preprocessdf(test_df)\n",
        "\n",
        "# Create sentence and label lists\n",
        "text_a = test_df.question1\n",
        "text_b=test_df.question2\n",
        "is_dup=test_df.is_duplicate\n",
        "#print(text_a)\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "labels=list()\n",
        "questions=list()\n",
        "m,n=test_df.shape\n",
        "for w in range(m):\n",
        "  q1=test_df.iloc[w,2]\n",
        "  #print(q1)\n",
        "  q2=test_df.iloc[w,3]\n",
        "  #print(q2)\n",
        "  is_d=int(float(test_df.iloc[w,4]))\n",
        "  #print(is_d)\n",
        "  if(q1==\"question1\"):\n",
        "    continue\n",
        "  questions.append(\"[CLS] \" + str(q1) + \" [SEP] \" +str(q2)+ \" [SEP]\")\n",
        "  #print(is_d)\n",
        "  labels.append(is_d)\n",
        "#labels = df.is_duplicate.values\n",
        "labels=np.asarray(labels)\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary: 2854\n",
            "Average sequence length:  33\n",
            "Number of duplicate questions:  500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf7Can-1Eus7",
        "colab_type": "code",
        "outputId": "9e59a4f4-3399-4be4-eedd-921c17bebcfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(test_df.shape)\n",
        "print(len(questions))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 5)\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXBYMc0No5r0",
        "colab_type": "code",
        "outputId": "672adc05-ffaf-4a96-cbde-7926f685f06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.encode(sent[:MAX_LEN]) for sent in questions]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "#print (tokenized_texts[1])"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnpqFqYnpm1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = pad_sequences(tokenized_texts, maxlen=MAX_LEN, dtype=\"long\",value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP6M206eqFgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  att_mask = [int(token_id > 0) for token_id in seq]\n",
        "  attention_masks.append(att_mask)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfSXRRfYqLXw",
        "colab_type": "code",
        "outputId": "238f79e8-bc32-4444-b295-ff76407dbdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "prediction_inputs=input_ids\n",
        "prediction_labels=labels\n",
        "prediction_masks=attention_masks\n",
        "print(prediction_inputs.shape)\n",
        "print(prediction_labels.shape)\n",
        "print(len(prediction_masks))\n"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 80)\n",
            "(1000,)\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOEUZRfso-UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "prediction_inputs = torch.tensor(prediction_inputs)\n",
        "prediction_labels = torch.tensor(prediction_labels)\n",
        "prediction_masks = torch.tensor(prediction_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsPRebtXTfjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 8\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EmsdXHpR_Qr",
        "colab_type": "code",
        "outputId": "1d9f69f1-b6f8-434a-ab26-c9ccbb919365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qti7EByKPkEu",
        "colab_type": "code",
        "outputId": "bf1b1941-eb4c-4adf-95fd-f9265e6bfb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "print(\"Final Accuracy: \",accuracy_score(flat_true_labels, flat_predictions))\n",
        "print(\"Precision: \", precision_score(flat_true_labels, flat_predictions))\n",
        "print(\"Recall: \", recall_score(flat_true_labels, flat_predictions))"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Accuracy:  0.993\n",
            "Precision:  1.0\n",
            "Recall:  0.986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pxf47CvS6E4",
        "colab_type": "code",
        "outputId": "7e332764-5a41-4400-ca60-748a9950446f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "k=0\n",
        "total_incorrect=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  if(int(float(flat_true_labels[i]))!=int(float(test_df.iloc[i,4]))):\n",
        "    print(\"Not correct\")  \n",
        "wrpos=0\n",
        "wrneg=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  pred=int(float(flat_predictions[i]))\n",
        "  real=int(float(flat_true_labels[i]))\n",
        "  if(pred!=real):\n",
        "    total_incorrect+=1\n",
        "    if(flat_true_labels[i]==1):\n",
        "      wrpos+=1\n",
        "    else:\n",
        "      wrneg+=1  \n",
        "    if(k<=11):\n",
        "      print(\"\\n-----------------------------\\n\",test_df.iloc[i,2]+\"\\n\",test_df.iloc[i,3]+\"\\nActual Value: \",test_df.iloc[i,4]+\", \",flat_true_labels[i])\n",
        "    k+=1\n",
        "print(\"Incorrect examples: \",total_incorrect) \n",
        "print(\"Incorrect positive examples: \",wrpos)\n",
        "print(\"incorrect negative examples: \",wrneg)\n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-----------------------------\n",
            " would happen unblurred nongoogle street view europe suddenly appeared online\n",
            " suddenly became legal make google street view european countries delete unblurred backups afterwards would happen next\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " monetize youtube videos upload copyright content chances google may block account\n",
            " upload movies youtube monetize issue copyright\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " shepherdretriever mixed puppy chewing shoes\n",
            " stop beaglepointer mix puppy biting shoes\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " array allocate dynamic memory\n",
            " dynamic allocations array allowed c\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " write effective cover letter job software engineer\n",
            " would recommend write cvcover letter software engineer\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " create new shell new terminal using c programming linux terminal\n",
            " create new terminal new shell linux using c programming\n",
            "Actual Value:  1.0,  1\n",
            "\n",
            "-----------------------------\n",
            " java considered pure objectoriented programming language\n",
            " java 100 object oriented programming language\n",
            "Actual Value:  1.0,  1\n",
            "Incorrect examples:  7\n",
            "Incorrect positive examples:  7\n",
            "incorrect negative examples:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-h4UBzKiam5",
        "colab_type": "code",
        "outputId": "cfde3e7b-15d0-40ac-e5a3-7dfd134a23d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "k=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  if(int(flat_true_labels[i])!=int(test_df.iloc[i,4])):\n",
        "    print(\"Not correct\")  \n",
        "wrpos=0\n",
        "wrneg=0\n",
        "for i in range(len(flat_predictions)):\n",
        "  pred=int(float(flat_predictions[i]))\n",
        "  real=int(float(flat_true_labels[i]))\n",
        "  if(pred!=real):\n",
        "    if(flat_true_labels[i]==1):\n",
        "      wrpos+=1\n",
        "    else:\n",
        "      wrneg+=1  \n",
        "    if(k<=11):\n",
        "      print(\"\\n-----------------------------\\n\",test_df.iloc[i,2]+\"\\n\",test_df.iloc[i,3]+\"\\nActual Value: \",test_df.iloc[i,4]+\", \",flat_true_labels[i])\n",
        "    k+=1\n",
        "print(\"Incorrect examples: \",k) \n",
        "print(\"Incorrect positive examples: \",wrpos)\n",
        "print(\"incorrect negative examples: \",wrneg)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-dd6314647774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_true_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not correct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwrpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0.0'"
          ]
        }
      ]
    }
  ]
}